# -*- coding: utf-8 -*-
"""analisis_hotel_medan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1q6TGapnueA4P-sBEJiHG5d9ZawoDafP6
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

from sklearn.tree import DecisionTreeClassifier
from keras.models import Sequential
from wordcloud import WordCloud
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn import metrics 
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import mean_absolute_percentage_error,mean_squared_error,r2_score

data= pd.read_csv('/content/drive/MyDrive/hotel jw_marriot_mdn/data_stemming.csv')

data.head()

"""steming"""

#casefolding

import re
def casefolding(ulasan):
  ulasan = str(ulasan).lower()
  ulasan = ulasan.strip("")
  ulasan = re.sub(r'[?|$|.|!2_:@\/#")(-+]','', ulasan)
  return ulasan
data['ulasan'] = data['ulasan'].apply(casefolding)
data.head()

#tokenizing
def token(ulasan):
    nstr =ulasan.split(',')
    dat=[]
    a = -1 
    for hu in nstr:
        a = a + 1
    if hu == '':
        dat.append(a)
    p = 0
    b = 0
    for q in dat:
        b = q - p
        del nstr[b]
        p = p + 1
    return nstr
data['ulasan'] = data['ulasan'].apply(token)
data.head(10)

#proses filtering
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
def stopword_removal(ulasan):
    filtering = stopwords.words('indonesian','english')
    x = []
    data = []
    def myFunc(x):
      if x in filtering:
        return False
      else:
        return True
    fit = filter(myFunc, ulasan)
    for x in fit:
        data.append(x)
    return data
data['ulasan'] = data['ulasan'].apply(stopword_removal)
data.head()

# proses steming

from sklearn.pipeline import Pipeline
!pip install Sastrawi
from Sastrawi.Stemmer.StemmerFactory import StemmerFactory

def stemming(ulasan):
  factory = StemmerFactory()
  stemmer = factory.create_stemmer()
  do = []
  for w in ulasan:
      dt = stemmer.stem(w)
      do.append(dt)
  d_clean=[]
  d_clean= "".join(do)
  print(d_clean)
  return d_clean
data['ulasan'] = data['ulasan'].apply(stemming)

data.to_csv('data_stemming.csv', index=False)
data_clean = pd.read_csv('data_stemming.csv', encoding='latin1')
data_clean.head()

#konversi label ke polarisasi
def convert(rating):
  if rating >= 5.1 :
    return ('Positif')
  else:
    return ('Negatif')

data['rating'] = data['rating'].apply(convert)

data.info()

data['rating'].value_counts()

#visualizing the count of languages in the dataset
sns.set_style("darkgrid")
ls=data['rating'].value_counts().head(15).sort_values(ascending=False)
plt.figure(figsize=(12,8))
temp =sns.barplot(ls.index, ls.values,alpha=0.8)
plt.ylabel('COUNT', fontsize=14)
plt.xlabel('rating', fontsize=28)
temp.set_xticklabels(rotation=90,labels=ls.index,fontsize=15)
plt.show()

#proses TF IDF dan

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer

tf = TfidfVectorizer()
text_tf = tf.fit_transform(data['ulasan'].astype('U'))
text_tf

#splitting data

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split
(text_tf, data['rating'], test_size=0.2, random_state=42)

tfidf = TfidfVectorizer() 
X = tfidf.fit_transform(data['ulasan'].astype('U'))
Y = data['rating']

log_reg = LogisticRegression().fit(X, Y)

#predict on train 
train_predsLog = log_reg.predict(x_train)
#accuracy on train

#predict on test
test_predsLog = log_reg.predict(x_test)
#accuracy on test
print("\n confusion_matrix train is: \n", confusion_matrix(y_train, train_predsLog))
print('-'*50)
print("\n confusion_matrix test is: \n", confusion_matrix(y_test, test_predsLog))
print('-'*50)
print("Model accuracy on train is: ", accuracy_score(y_train, train_predsLog))
print("Model accuracy on test is: ", accuracy_score(y_test, test_predsLog))
print('-'*50)
print(classification_report(y_test, test_predsLog))

DT = DecisionTreeClassifier().fit(X,Y)
#predict on train 
train_preds2 = DT.predict(x_train)
#accuracy on train
print("Model accuracy on train is: ", accuracy_score(y_train, train_preds2))

#predict on test
test_preds2 = DT.predict(x_test)
#accuracy on test
print("Model accuracy on test is: ", accuracy_score(y_test, test_preds2))
print('-'*50)

#Confusion matrix
print("confusion_matrix train is: ", confusion_matrix(y_train, train_preds2))
print("confusion_matrix test is: ", confusion_matrix(y_test, test_preds2))
print('Wrong predictions out of total')
print('-'*50)

# Wrong Predictions made.
print((y_test !=test_preds2).sum(),'/',((y_test == test_preds2).sum()+(y_test != test_preds2).sum()))
print('-'*50)

# Kappa Score
print('KappaScore is: ', metrics.cohen_kappa_score(y_test,test_preds2))

#fit the model on train data 
SVM = SVC(kernel='linear')
SVM.fit(X, Y)

#predict on train 
train_preds5 = SVM.predict(x_train)
#accuracy on train

#predict on test
test_preds5 = SVM.predict(x_test)
#accuracy on test

#Confusion matrix
print("confusion_matrix train is: ", confusion_matrix(y_train, train_preds5))
print("confusion_matrix test is: ", confusion_matrix(y_test, test_preds5))
print('-'*50)
print("Model accuracy on train is: ", accuracy_score(y_train, train_preds5))
print("Model accuracy on test is: ", accuracy_score(y_test, test_preds5))

print('-'*50)
print(classification_report(y_test, test_preds5))
# Kappa Score
print('KappaScore is: ', metrics.cohen_kappa_score(y_test,test_preds5))

# import XGBClassifier
from xgboost import XGBClassifier
# declare parameters
params = {
            'objective':'binary:logistic',
            'max_depth': 4,
            'alpha': 10,
            'learning_rate': 1.0,
            'n_estimators':100
        }        
# instantiate the classifier 
xgb_clf = XGBClassifier(**params)
# fit the classifier to the training data
xgb_clf.fit(x_train, y_train)
print(xgb_clf)

y_pred = xgb_clf.predict(x_test)
from sklearn.metrics import accuracy_score

print('XGBoost model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))